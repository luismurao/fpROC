RcppArmadillo::RcppArmadillo.package.skeleton(name = "fpROC", list = character(),
environment = .GlobalEnv, path = ".", force = FALSE,
code_files = character(), example_code = TRUE)
devtools::document()
devtools::document()
devtools::install()
devtools::build()
devtools::document()
//' @title Calculate area under curve (AUC) using trapezoidal rule
//' @title Calculate area under curve (AUC) using trapezoidal rule
test <- rnorm(100)
train <- rnorm(1000)
bigclass_mat_opt(test, train)
install.packages("RcppParallel")
devtools::install()
devtools::install()
devtools::install(build_opts = c("--verbose"))
devtools::install()
# In R:
remove.packages("fpROC")
devtools::clean_dll()
devtools::install(dependencies = TRUE, build_vignettes = FALSE)
install.packages("RcppParallel", type = "source")
# In R:
devtools::clean_dll()
devtools::install(build_opts = c("--clean"))
# In R:
devtools::clean_dll()
devtools::install(pkg = ".",build_opts = c("--clean"))
Sys.setenv(RCPP_PARALLEL_USE_TBB=1)
RcppParallel::defaultNumThreads()
#' Calculate Partial Area Under the Curve (AUC) Metrics
#'
#' Computes partial AUC ratios between model predictions and random curves at a specified threshold,
#' with options for sampling and iterations. Handles both numeric vectors and SpatRaster inputs.
#'
#' @param test_prediction Numeric vector of test prediction values (e.g., model outputs)
#' @param prediction Numeric vector or SpatRaster object containing prediction values
#' @param threshold Percentage threshold for partial AUC calculation (default = 5)
#' @param sample_percentage Percentage of test data to sample (default = 50)
#' @param iterations Number of iterations for random curve generation (default = 500)
#'
#' @return A list containing:
#' \itemize{
#'   \item If input has no variability: List with NA values for AUC metrics
#'   \item Otherwise: Matrix of AUC results from \code{auc_par_arma_opt}
#' }
#'
#' @details
#' The function calculates partial AUC ratios by:
#' \enumerate{
#'   \item Validating input types and completeness
#'   \item Handling NA values and SpatRaster conversion
#'   \item Checking for prediction variability
#'   \item Computing AUC metrics using optimized C++ code
#' }
#'
#' When prediction values have no variability (all equal), the function returns NA values with a warning.
#'
#' @examples
#' \dontrun{
#' # With numeric vectors
#' test_data <- rnorm(100)
#' pred_data <- rnorm(100)
#' result <- auc_part(test_prediction = test_data, prediction = pred_data)
#'
#' # With SpatRaster
#' library(terra)
#' r <- rast(ncol=10, nrow=10)
#' values(r) <- rnorm(ncell(r))
#' result <- auc_part(test_prediction = test_data, prediction = r)
#' }
#'
#' @export
#' @import RcppArmadillo
#' @importFrom stats na.omit
#' @importFrom RcppParallel RcppParallelLibs
#' @seealso \code{\link{auc_par_arma_opt}} for the underlying C++ implementation
#' @useDynLib fpROC, .registration=TRUE
auc_part <-function (test_prediction, prediction, threshold = 5, sample_percentage = 50,
iterations = 500) {
if (missing(prediction)) {
stop("Argument 'prediction' is necessary to perform the analysis.")
}
if (missing(test_prediction)) {
stop("Argument 'test_prediction' is necessary to perform the analysis.")
}
c_pred <- class(prediction)[1]
if (!c_pred %in% c("SpatRaster", "numeric")) {
stop("'prediction' must be of class 'SpatRaster' or 'numeric'.")
}
c_tdat <- class(test_prediction)[1]
if (c_tdat != "numeric") {
stop("'test_prediction' must be of class 'numeric'.")
}
if (c_pred == "SpatRaster") {
prediction <- prediction[][,1]
}
prediction <- prediction[!is.na(prediction)]
mmx <- range(prediction)
test_prediction <- stats::na.omit(test_prediction)
if (mmx[1] == mmx[2]) {
warning("\nprediction has no variability, pROC will return NA.\n")
p_roc <- rep(NA, 2)
names(p_roc) <- c(paste0("Mean_AUC_ratio_at_", threshold,
"%"), "pval_pROC")
auc_ratios <- rep(NA, 3)
names(auc_ratios) <- c("Model_partial_AUC", "Random_curve_partial_AUC",
"AUC_ratio")
p_roc_res <- list(pROC_summary = p_roc, pROC_results = auc_ratios)
}
else {
partial_AUC <- auc_par_arma_opt(test_prediction = test_prediction,
prediction = prediction,
threshold = threshold,
sample_percentage = sample_percentage,
iterations = iterations)
return(partial_AUC)
}
return(p_roc_res)
}
test_data <- rnorm(100)
pred_data <- rnorm(100)
result <- auc_part(test_prediction = test_data, prediction = pred_data)
result <- auc_part(test_prediction = test_data, prediction = pred_data)
result <- auc_part(test_prediction = test_data, prediction = pred_data)
# Clean previous builds
devtools::clean_dll()
# Reinstall
devtools::install()
# In R
devtools::clean_dll()
remove.packages("fpROC")
library(Rcpp)
library(roxygen2)
Rcpp::compileAttributes()           # this updates the Rcpp layer from C++ to R
roxygen2::roxygenize(roclets="r
roxygen2::roxygenize(roclets="rd")  # this updates the documentation
## ----out.width = '100%'-----------------------------------------------------
library(bamm)
pg_sparse <- bamm::model2sparse(model = modelos[[1]],
threshold =  umbrales_bin[[1]])
auc_par_arma_opt
//' Calculate Area Under Curve (AUC) Using Trapezoidal Rule
devtools::document()
?fpROC
library(fpROC)
?fpROC
test_data <- rnorm(100)
pred_data <- rnorm(100)
result <- fpROC::auc_parallel(test_prediction = test_data, prediction = pred_data)
testthat::expect_match(class(result$summary)[1],"matrix")
result <- fpROC::auc_metrics(test_prediction = test_data, prediction = pred_data)
testthat::expect_match(class(result$summary)[1],"matrix")
result
result <- fpROC::auc_parallel(test_prediction = test_data, prediction = pred_data)
result
result <- fpROC::auc_metrics(test_prediction = test_data, prediction = pred_data)
result
devtools::document()
test_data <- rnorm(100)
pred_data <- rnorm(100)
result <- auc_metrics(test_prediction = test_data, prediction = pred_data)
# With SpatRaster
library(terra)
r <- terra::rast(ncol=10, nrow=10)
values(r) <- rnorm(ncell(r))
result <- auc_metrics(test_prediction = test_data, prediction = r)
result <- fpROC::auc_metrics(test_prediction = test_data, prediction = pred_data)
?fpROC
# ----------------------------------------------------------------------------
# C++ functions
auc_metr <- fpROC::auc_parallel(
test_prediction = test_prediction,
prediction = prediction,
threshold = threshold,
sample_percentage = sample_percentage,
iterations = iterations,compute_full_auc = compute_full_auc
)
test_data <- rnorm(100)
pred_data <- rnorm(100)
result <- fpROC::auc_metrics(test_prediction = test_data, prediction = pred_data)
test_prediction = test_data
prediction = pred_data
threshold = 5
sample_percentage = 50
compute_full_auc = TRUE
iterations = 500
if (missing(prediction) || missing(test_prediction)) {
stop("Both 'prediction' and 'test_prediction' are required")
}
if (!inherits(test_prediction, "numeric")) {
stop("'test_prediction' must be numeric")
}
# Handle SpatRaster input
if (inherits(prediction, "SpatRaster")) {
prediction <- terra::values(prediction, na.rm = TRUE)
} else if (!inherits(prediction, "numeric")) {
stop("'prediction' must be numeric or SpatRaster")
}
prediction <- stats::na.omit(prediction)
test_prediction <- stats::na.omit(test_prediction)
# Check for variability
if (diff(range(prediction)) == 0) {
warning("No variability in predictions, returning NA")
return(list(
pROC_summary = c(
AUC_ratio = NA,
p_value = NA
),
pROC_results = c(
Model_AUC = NA,
Random_AUC = NA,
AUC_ratio = NA
)
))
}
# ----------------------------------------------------------------------------
# C++ functions
auc_metr <- fpROC::auc_parallel(
test_prediction = test_prediction,
prediction = prediction,
threshold = threshold,
sample_percentage = sample_percentage,
iterations = iterations,compute_full_auc = compute_full_auc
)
auc_metr
summ_auc_metrics <- summarize_auc_results(auc_metr,compute_full_auc)
summ_auc_metrics
# ----------------------------------------------------------------------------
colnames(auc_metrics) <- c("Model_full_auc",
"Model_partial_AUC",
"Random_curve_partial_AUC",
"AUC_ratio")
auc_metrics
# ----------------------------------------------------------------------------
colnames(auc_metr) <- c("Model_full_auc",
"Model_partial_AUC",
"Random_curve_partial_AUC",
"AUC_ratio")
colnames(summ_auc_metrics) <- c("Mean_Model_full_auc",
paste0("Mean_Model_partial_AUC_at_",
threshold,"_percent"),
"Mean_Random_curve_partial_AUC",
"Mean_AUC_ratio",
"pval_pROC")
list(summary = summ_auc_metrics,
proc_results = auc_metr)
summ_auc_metrics <- fpROC::summarize_auc_results(auc_metr,compute_full_auc)
summ_auc_metrics <- fpROC::summarize_auc_results(auc_metr,compute_full_auc)
summ_auc_metrics
summ_auc_metrics
summ_auc_metrics <- fpROC::summarize_auc_results(auc_metr,compute_full_auc)
summ_auc_metrics
summ_auc_metrics <- fpROC::summarize_auc_results(auc_metr,compute_full_auc)
summ_auc_metrics
summ_auc_metrics <- fpROC::summarize_auc_results(auc_metr,compute_full_auc)
summ_auc_metrics
summ_auc_metrics
summ_auc_metrics
//' Summarize Bootstrap AUC Results
test_data <- rnorm(100)
pred_data <- rnorm(100)
result <- fpROC::auc_metrics(test_prediction = test_data, prediction = pred_data)
result
result <- fpROC::auc_metrics(test_prediction = test_data, prediction = pred_data,compute_full_auc = FALSE)
result
test_data
test_data <- abs(rnorm(100))
test_data <- abs(rnorm(100))
pred_data <- abs(rnorm(100))
result <- fpROC::auc_metrics(test_prediction = test_data, prediction = pred_data,compute_full_auc = FALSE)
result
result <- fpROC::auc_metrics(test_prediction = test_data,
prediction = pred_data,
compute_full_auc = TRUE)
result
testthat::expect_match(class(result$summary)[1],"matrix")
testthat::expect_match(class(result$proc_results)[1],"matrix")
test_that("pROC metrics, pAUC ratios between model predictions and random", {
test_data <- abs(rnorm(100))
pred_data <- abs(rnorm(100))
result <- fpROC::auc_metrics(test_prediction = test_data,
prediction = pred_data,
compute_full_auc = TRUE)
testthat::expect_match(class(result$summary)[1],"matrix")
testthat::expect_match(class(result$proc_results)[1],"matrix")
})
test_data <- rnorm(100)
r <- terra::rast(ncol=10, nrow=10)
terra::values(r) <- rnorm(terra::ncell(r))
result <-  fpROC::auc_metrics(test_prediction = test_data, prediction = r)
testthat::expect_match(class(result$summary)[1],"matrix")
result
result$proc_results[,5]
result$proc_results[,4]
test_that("pROC metrics, pAUC ratios between raster model predictions and random", {
test_data <- rnorm(100)
r <- terra::rast(ncol=10, nrow=10)
terra::values(r) <- rnorm(terra::ncell(r))
result <-  fpROC::auc_metrics(test_prediction = test_data, prediction = r)
testthat::expect_match(class(result$summary)[1],"matrix")
testthat::expect_match(class(result$proc_results)[1],"matrix")
})
library(testthat)
library(fpROC)
test_that("pROC metrics, pAUC ratios between model predictions and random", {
test_data <- abs(rnorm(100))
pred_data <- abs(rnorm(100))
result <- fpROC::auc_metrics(test_prediction = test_data,
prediction = pred_data,
compute_full_auc = TRUE)
testthat::expect_match(class(result$summary)[1],"matrix")
testthat::expect_match(class(result$proc_results)[1],"matrix")
})
test_that("pROC metrics, pAUC ratios between raster model predictions and random", {
test_data <- rnorm(100)
r <- terra::rast(ncol=10, nrow=10)
terra::values(r) <- rnorm(terra::ncell(r))
result <-  fpROC::auc_metrics(test_prediction = test_data, prediction = r)
testthat::expect_match(class(result$summary)[1],"matrix")
testthat::expect_match(class(result$proc_results)[1],"matrix")
})
# Basic usage with random data
set.seed(123)
train_pred <- runif(1000)   # Training predictions
test_pred <- runif(500)     # Test predictions
# Compute only partial AUC metrics (500 iterations)
results <- auc_parallel(test_pred, train_pred,
threshold = 5.0,
iterations = 100)  # Reduced for example
# Summarize results (assume complete AUC was not computed)
summary <- summarize_auc_results(results, has_complete_auc = FALSE)
testthat::expect_match(class(summary)[1],"matrix")
library(testthat)
library(fpROC)
test_that("pROC metrics, pAUC ratios between model predictions and random", {
test_data <- abs(rnorm(100))
pred_data <- abs(rnorm(100))
result <- fpROC::auc_metrics(test_prediction = test_data,
prediction = pred_data,
compute_full_auc = TRUE)
testthat::expect_match(class(result$summary)[1],"matrix")
testthat::expect_match(class(result$proc_results)[1],"matrix")
})
test_that("pROC metrics, pAUC ratios between raster model predictions and random", {
test_data <- rnorm(100)
r <- terra::rast(ncol=10, nrow=10)
terra::values(r) <- rnorm(terra::ncell(r))
result <-  fpROC::auc_metrics(test_prediction = test_data, prediction = r)
testthat::expect_match(class(result$summary)[1],"matrix")
testthat::expect_match(class(result$proc_results)[1],"matrix")
})
test_that("Summary of AUC and pAUC results",{
# Basic usage with random data
set.seed(123)
train_pred <- runif(1000)   # Training predictions
test_pred <- runif(500)     # Test predictions
# Compute only partial AUC metrics (500 iterations)
results <- auc_parallel(test_pred, train_pred,
threshold = 5.0,
iterations = 100)  # Reduced for example
# Summarize results (assume complete AUC was not computed)
summary <- summarize_auc_results(results, has_complete_auc = FALSE)
testthat::expect_match(class(summary)[1],"matrix")
})
library(testthat)
library(fpROC)
test_that("pROC metrics, pAUC ratios between model predictions and random", {
test_data <- abs(rnorm(100))
pred_data <- abs(rnorm(100))
result <- fpROC::auc_metrics(test_prediction = test_data,
prediction = pred_data,
compute_full_auc = TRUE)
testthat::expect_match(class(result$summary)[1],"matrix")
testthat::expect_match(class(result$proc_results)[1],"matrix")
})
test_that("pROC metrics, pAUC ratios between raster model predictions and random", {
test_data <- rnorm(100)
r <- terra::rast(ncol=10, nrow=10)
terra::values(r) <- rnorm(terra::ncell(r))
result <-  fpROC::auc_metrics(test_prediction = test_data, prediction = r)
testthat::expect_match(class(result$summary)[1],"matrix")
testthat::expect_match(class(result$proc_results)[1],"matrix")
})
test_that("Summary of AUC and pAUC results",{
# Basic usage with random data
set.seed(123)
train_pred <- runif(1000)   # Training predictions
test_pred <- runif(500)     # Test predictions
# Compute only partial AUC metrics (500 iterations)
results <- auc_parallel(test_pred, train_pred,
threshold = 5.0,
iterations = 100)  # Reduced for example
# Summarize results (assume complete AUC was not computed)
summary <- summarize_auc_results(results, has_complete_auc = FALSE)
testthat::expect_match(class(summary)[1],"matrix")
})
test_that("AUC computation",{
x <- c(0, 0.5, 1, 1.5, 2)
y <- c(0, 0.7, 0.9, 0.95, 1)
auc <- trap_roc(x, y)  # Returns AUC
testthat::expect_match(class(auc),"numeric")
})
?auc_metrics
terra::rast(ncol=10, nrow=10)
```R
```R
```R
library(terra)
r <- terra::rast(ncol=10, nrow=10)
values(r) <- rnorm(ncell(r))
result <- auc_metrics(test_prediction = test_data, prediction = r)
```R
# With SpatRaster
library(terra)
r <- terra::rast(ncol=10, nrow=10)
values(r) <- rnorm(ncell(r))
result <- fpROC::auc_metrics(test_prediction = test_data, prediction = r)
result
```R
set.seed(999)
# With SpatRaster
library(terra)
r <- terra::rast(ncol=10, nrow=10)
values(r) <- rnorm(ncell(r))
result <- fpROC::auc_metrics(test_prediction = test_data, prediction = r)
result
set.seed(999)
# With SpatRaster
library(terra)
r <- terra::rast(ncol=10, nrow=10)
values(r) <- rnorm(ncell(r))
result <- fpROC::auc_metrics(test_prediction = test_data, prediction = r)
result$summary
usethis::use_github_actions()
usethis::gh_token_help()
usethis::edit_r_environ()

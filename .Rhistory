RcppArmadillo::RcppArmadillo.package.skeleton(name = "fpROC", list = character(),
environment = .GlobalEnv, path = ".", force = FALSE,
code_files = character(), example_code = TRUE)
devtools::document()
devtools::document()
devtools::install()
devtools::build()
devtools::document()
//' @title Calculate area under curve (AUC) using trapezoidal rule
//' @title Calculate area under curve (AUC) using trapezoidal rule
test <- rnorm(100)
train <- rnorm(1000)
bigclass_mat_opt(test, train)
install.packages("RcppParallel")
devtools::install()
devtools::install()
devtools::install(build_opts = c("--verbose"))
devtools::install()
# In R:
remove.packages("fpROC")
devtools::clean_dll()
devtools::install(dependencies = TRUE, build_vignettes = FALSE)
install.packages("RcppParallel", type = "source")
# In R:
devtools::clean_dll()
devtools::install(build_opts = c("--clean"))
# In R:
devtools::clean_dll()
devtools::install(pkg = ".",build_opts = c("--clean"))
Sys.setenv(RCPP_PARALLEL_USE_TBB=1)
RcppParallel::defaultNumThreads()
#' Calculate Partial Area Under the Curve (AUC) Metrics
#'
#' Computes partial AUC ratios between model predictions and random curves at a specified threshold,
#' with options for sampling and iterations. Handles both numeric vectors and SpatRaster inputs.
#'
#' @param test_prediction Numeric vector of test prediction values (e.g., model outputs)
#' @param prediction Numeric vector or SpatRaster object containing prediction values
#' @param threshold Percentage threshold for partial AUC calculation (default = 5)
#' @param sample_percentage Percentage of test data to sample (default = 50)
#' @param iterations Number of iterations for random curve generation (default = 500)
#'
#' @return A list containing:
#' \itemize{
#'   \item If input has no variability: List with NA values for AUC metrics
#'   \item Otherwise: Matrix of AUC results from \code{auc_par_arma_opt}
#' }
#'
#' @details
#' The function calculates partial AUC ratios by:
#' \enumerate{
#'   \item Validating input types and completeness
#'   \item Handling NA values and SpatRaster conversion
#'   \item Checking for prediction variability
#'   \item Computing AUC metrics using optimized C++ code
#' }
#'
#' When prediction values have no variability (all equal), the function returns NA values with a warning.
#'
#' @examples
#' \dontrun{
#' # With numeric vectors
#' test_data <- rnorm(100)
#' pred_data <- rnorm(100)
#' result <- auc_part(test_prediction = test_data, prediction = pred_data)
#'
#' # With SpatRaster
#' library(terra)
#' r <- rast(ncol=10, nrow=10)
#' values(r) <- rnorm(ncell(r))
#' result <- auc_part(test_prediction = test_data, prediction = r)
#' }
#'
#' @export
#' @import RcppArmadillo
#' @importFrom stats na.omit
#' @importFrom RcppParallel RcppParallelLibs
#' @seealso \code{\link{auc_par_arma_opt}} for the underlying C++ implementation
#' @useDynLib fpROC, .registration=TRUE
auc_part <-function (test_prediction, prediction, threshold = 5, sample_percentage = 50,
iterations = 500) {
if (missing(prediction)) {
stop("Argument 'prediction' is necessary to perform the analysis.")
}
if (missing(test_prediction)) {
stop("Argument 'test_prediction' is necessary to perform the analysis.")
}
c_pred <- class(prediction)[1]
if (!c_pred %in% c("SpatRaster", "numeric")) {
stop("'prediction' must be of class 'SpatRaster' or 'numeric'.")
}
c_tdat <- class(test_prediction)[1]
if (c_tdat != "numeric") {
stop("'test_prediction' must be of class 'numeric'.")
}
if (c_pred == "SpatRaster") {
prediction <- prediction[][,1]
}
prediction <- prediction[!is.na(prediction)]
mmx <- range(prediction)
test_prediction <- stats::na.omit(test_prediction)
if (mmx[1] == mmx[2]) {
warning("\nprediction has no variability, pROC will return NA.\n")
p_roc <- rep(NA, 2)
names(p_roc) <- c(paste0("Mean_AUC_ratio_at_", threshold,
"%"), "pval_pROC")
auc_ratios <- rep(NA, 3)
names(auc_ratios) <- c("Model_partial_AUC", "Random_curve_partial_AUC",
"AUC_ratio")
p_roc_res <- list(pROC_summary = p_roc, pROC_results = auc_ratios)
}
else {
partial_AUC <- auc_par_arma_opt(test_prediction = test_prediction,
prediction = prediction,
threshold = threshold,
sample_percentage = sample_percentage,
iterations = iterations)
return(partial_AUC)
}
return(p_roc_res)
}
test_data <- rnorm(100)
pred_data <- rnorm(100)
result <- auc_part(test_prediction = test_data, prediction = pred_data)
result <- auc_part(test_prediction = test_data, prediction = pred_data)
result <- auc_part(test_prediction = test_data, prediction = pred_data)
# Clean previous builds
devtools::clean_dll()
# Reinstall
devtools::install()
# In R
devtools::clean_dll()
remove.packages("fpROC")
library(Rcpp)
library(roxygen2)
Rcpp::compileAttributes()           # this updates the Rcpp layer from C++ to R
roxygen2::roxygenize(roclets="r
roxygen2::roxygenize(roclets="rd")  # this updates the documentation
## ----out.width = '100%'-----------------------------------------------------
library(bamm)
pg_sparse <- bamm::model2sparse(model = modelos[[1]],
threshold =  umbrales_bin[[1]])
auc_par_arma_opt
224.302/11.094
## set personal access token:
#usethis::edit_r_environ()
usethis::git_sitrep()
rhub::rhub_setup() # Commit, push, merge
rhub::rhub_setup() # Commit, push, merge
rhub::rhub_doctor()
rhub::rhub_platforms()
rhub::rhub_check(platforms = c("linux","macos",
"macos-arm64","windows",
"ubuntu-clang"))# launch manually
# Add comments for CRAN
usethis::use_cran_comments(open = rlang::is_interactive())
# Upgrade version number
usethis::use_version(which = c("patch", "minor", "major", "dev")[1])
covr::package_coverage()
covr::codecov()
covr::code_coverage()
report()
covr::report()
set.seed(123)
train_pred <- runif(1000)   # Training predictions
test_pred <- train_pred     # Test predictions
# Compute only partial AUC metrics (500 iterations)
results <- fpROC::auc_parallel(test_pred, train_pred,
threshold = 5.0,
iterations = 100)  # Reduced for example
train_pred <- runif(100)   # Training predictions
test_pred <- train_pred     # Test predictions
# Compute only partial AUC metrics (500 iterations)
results <- fpROC::auc_parallel(test_pred, train_pred,
threshold = 5.0,
iterations = 100)  # Reduced for example
results
# Compute only partial AUC metrics (500 iterations)
results <- fpROC::auc_parallel(test_pred,
threshold = 5.0,
iterations = 100)  # Reduced for example
# Compute only partial AUC metrics (500 iterations)
results <- fpROC::auc_parallel(test_pred, NA,
threshold = 5.0,
iterations = 100)  # Reduced for example
# Compute only partial AUC metrics (500 iterations)
results <- fpROC::auc_parallel(
threshold = 5.0,
iterations = 100)  # Reduced for example
results
# Compute only partial AUC metrics (500 iterations)
testthat::expect_error(fpROC::auc_parallel(
threshold = 5.0,
iterations = 100))  # Reduced for example
testthat::expect_error(fpROC::auc_parallel(test_prediction = 1,prediction = 1
threshold = 5.0,
testthat::expect_error(fpROC::auc_parallel(test_prediction = 1,prediction = 1,
threshold = 5.0,
iterations = 100))  #
testthat::expect_error(fpROC::auc_parallel(test_prediction = "1",
prediction = 1,
threshold = 5.0,
iterations = 100))  #
fpROC::auc_parallel(test_prediction = "1",
prediction = 1,
threshold = 5.0,
iterations = 100)
testthat::expect_error(fpROC::auc_parallel(
threshold = 5.0,
iterations = 100))  # Reduced for example
testthat::expect_error(fpROC::auc_parallel(test_prediction = "1",
prediction = train_pred,
threshold = 5.0,
iterations = 100))  #
testthat::expect_error(fpROC::auc_parallel(test_prediction = test_pred,
prediction = 1,
threshold = 5.0,
iterations = 100))  #
fpROC::auc_parallel(test_prediction = test_pred,
prediction = 1,
threshold = 5.0,
iterations = 100)
testthat::expect_error(fpROC::auc_metrics(test_prediction = "1",
prediction = train_pred,
threshold = 5.0,
iterations = 100))  #
fpROC::auc_metrics(test_prediction = "1",
prediction = train_pred,
threshold = 5.0,
iterations = 100)
fpROC::auc_metrics(
threshold = 5.0,
iterations = 100)
fpROC::auc_metrics(test_prediction = 1,
prediction = "1",
threshold = 5.0,
iterations = 100)
testthat::expect_error(fpROC::auc_metrics(test_prediction = 1,
prediction = rep(1,10),
threshold = 5.0,
iterations = 100))  #
#> ====================
hexSticker::geom_pkgname("fpROC")
imgurl <- "/home/luis/Dropbox/roc_rocp/images/PartialROC_ALeatorio.png"
sticker(imgurl, package="smop", p_size=20, s_x=1, s_y=.85, s_width=.6,
p_x = 1,p_y =1.65 ,
filename="inst/figures/imgfile.png",h_fill = "#F67500",
h_color = "#266491",spotlight = FALSE,l_alpha = 0.5)
library(hexSticker)
library(UCSCXenaTools)
#remotes::install_github("ropensci/UCSCXenaTools")
usethis::file
#> ====================
hexSticker::geom_pkgname("fpROC")
imgurl <- "/home/luis/Dropbox/roc_rocp/images/PartialROC_ALeatorio.png"
sticker(imgurl, package="smop", p_size=20, s_x=1, s_y=.85, s_width=.6,
p_x = 1,p_y =1.65 ,
filename="inst/figures/imgfile.png",h_fill = "#F67500",
h_color = "#266491",spotlight = FALSE,l_alpha = 0.5)
usethis::use_logo("inst/figures/imgfile.png")
pkgdown::build_favicons(overwrite = TRUE)
pkgdown::build_site()
#> ====================
hexSticker::geom_pkgname("fpROC")
imgurl <- "/home/luis/Dropbox/roc_rocp/images/PartialROC_ALeatorio.png"
sticker(imgurl, package="fpROC", p_size=20, s_x=1, s_y=.85, s_width=.6,
p_x = 1,p_y =1.65 ,
filename="inst/figures/imgfile.png",h_fill = "91C8E4",
h_color = "#266491",spotlight = FALSE,l_alpha = 0.5)
usethis::use_logo("inst/figures/imgfile.png")
usethis::use_logo("inst/figures/imgfile.png")
pkgdown::build_favicons(overwrite = TRUE)
pkgdown::build_site()
imgurl <- "/home/luis/Dropbox/roc_rocp/images/PartialROC_ALeatorio.png"
sticker(imgurl, package="fpROC", p_size=20, s_x=1, s_y=.85, s_width=.6,
p_x = 1,p_y =1.65 ,
filename="inst/figures/imgfile.png",h_fill = "#91C8E4",
h_color = "#266491",spotlight = FALSE,l_alpha = 0.5)
usethis::use_logo("inst/figures/imgfile.png")
usethis::use_logo("inst/figures/imgfile.png")
pkgdown::build_favicons(overwrite = TRUE)
pkgdown::build_site()
library(testthat)
library(fpROC)
testthat::test_that("pROC metrics, pAUC ratios between model predictions and random", {
test_data <- abs(rnorm(100))
pred_data <- abs(rnorm(100))
result <- fpROC::auc_metrics(test_prediction = test_data,
prediction = pred_data,
compute_full_auc = TRUE)
testthat::expect_match(class(result$summary)[1],"matrix")
testthat::expect_match(class(result$proc_results)[1],"matrix")
})
testthat::test_that("pROC metrics, pAUC ratios between raster model predictions and random", {
test_data <- rnorm(100)
r <- terra::rast(ncol=10, nrow=10)
terra::values(r) <- rnorm(terra::ncell(r))
result <-  fpROC::auc_metrics(test_prediction = test_data, prediction = r)
testthat::expect_match(class(result$summary)[1],"matrix")
testthat::expect_match(class(result$proc_results)[1],"matrix")
})
testthat::test_that("Summary of AUC and pAUC results",{
# Basic usage with random data
set.seed(123)
train_pred <- runif(1000)   # Training predictions
test_pred <- runif(500)     # Test predictions
# Compute only partial AUC metrics (500 iterations)
results <- fpROC::auc_parallel(test_pred, train_pred,
threshold = 5.0,
iterations = 100)  # Reduced for example
# Summarize results (assume complete AUC was not computed)
summary <- fpROC::summarize_auc_results(results, has_complete_auc = FALSE)
testthat::expect_match(class(summary)[1],"matrix")
})
testthat::test_that("AUC computation",{
x <- c(0, 0.5, 1, 1.5, 2)
y <- c(0, 0.7, 0.9, 0.95, 1)
auc <- fpROC::trap_roc(x, y)  # Returns AUC
testthat::expect_match(class(auc),"numeric")
})
testthat::test_that("No variability in model preds",{
set.seed(123)
train_pred <- runif(100)   # Training predictions
test_pred <- train_pred     # Test predictions
testthat::expect_error(fpROC::auc_metrics(
threshold = 5.0,
iterations = 100))  # Reduced for example
testthat::expect_error(fpROC::auc_metrics(test_prediction = "1",
prediction = train_pred,
threshold = 5.0,
iterations = 100))  #
testthat::expect_error(fpROC::auc_metrics(test_prediction = 1,
prediction = "1",
threshold = 5.0,
iterations = 100))  #
testthat::expect_error(fpROC::auc_metrics(test_prediction = 1,
prediction = rep(1,10),
threshold = 5.0,
iterations = 100))  #
})
fpROC::auc_metrics(test_prediction = 1,
prediction = rep(1,10),
threshold = 5.0,
iterations = 100)
testthat::expect_warning(fpROC::auc_metrics(test_prediction = 1,
prediction = rep(1,10),
threshold = 5.0,
iterations = 100))  #
testthat::test_that("No variability in model preds",{
set.seed(123)
train_pred <- runif(100)   # Training predictions
test_pred <- train_pred     # Test predictions
testthat::expect_error(fpROC::auc_metrics(
threshold = 5.0,
iterations = 100))  # Reduced for example
testthat::expect_error(fpROC::auc_metrics(test_prediction = "1",
prediction = train_pred,
threshold = 5.0,
iterations = 100))  #
testthat::expect_error(fpROC::auc_metrics(test_prediction = 1,
prediction = "1",
threshold = 5.0,
iterations = 100))  #
testthat::expect_warning(fpROC::auc_metrics(test_prediction = 1,
prediction = rep(1,10),
threshold = 5.0,
iterations = 100))  #
})
usethis::use_coverage()
covr::code_coverage()
covr::package_coverage()
covr::code_coverage()
covr::report()
pkgdown::build_site()
?pkgdown::build_site()
pkgdown::build_site()
set.seed(999)
# With numeric vectors
test_data <- rnorm(100)
pred_data <- rnorm(100)
result <- fpROC::auc_metrics(test_prediction = test_data, prediction = pred_data)
result
set.seed(999)
# With SpatRaster
library(terra)
r <- terra::rast(ncol=10, nrow=10)
values(r) <- rnorm(ncell(r))
result <- fpROC::auc_metrics(test_prediction = test_data, prediction = r)
result
## set personal access token:
#usethis::edit_r_environ()
usethis::git_sitrep()
rhub::rhub_setup() # Commit, push, merge
rhub::rhub_doctor()
rhub::rhub_platforms()
rhub::rhub_check(platforms = c("linux","macos",
"macos-arm64","windows",
"ubuntu-clang"))# launch manually
# Check content
# install.packages('checkhelper', repos = 'https://thinkr-open.r-universe.dev')
checkhelper::find_missing_tags()
# Check spelling
# usethis::use_spell_check()
spelling::spell_check_package()
# Check URL are correct
# install.packages('urlchecker', repos = 'https://r-lib.r-universe.dev')
urlchecker::url_check()
usethis::use_coverage()
?usethis::use_badge()
#
use_coverage(pkg = ".", type = c("codecov"))
library(devtools)
#
use_coverage(pkg = ".", type = c("codecov"))
#
use_coverage(type = c("codecov"))
library(covr)
codecov(token = "c0747062-bded-4984-a143-ce29fff40825")
use_coverage(pkg = ".", type = c("codecov"))
use_coverage(repo_spec = "luismurao/fpROC", type = c("codecov"))
use_coverage(repo_spec = "luismurao/fpROC")
# Add comments for CRAN
usethis::use_cran_comments(open = rlang::is_interactive())
test_data <- rnorm(100)
pred_data <- rnorm(100)
result <- fpROC::auc_metrics(test_prediction = test_data, prediction = pred_data)
# With SpatRaster
library(terra)
r <- terra::rast(ncol=10, nrow=10)
values(r) <- rnorm(ncell(r))
result <- auc_metrics(test_prediction = test_data, prediction = r)
result
use_readme_rmd(open = rlang::is_interactive())
usethis::use_readme_rmd(open = rlang::is_interactive())
use_readme_md(open = rlang::is_interactive())
usethis::use_readme_md(open = rlang::is_interactive())
library(fpROC)
?auc_parallel
bg_pred <- runif(1000)   # bg predictions
test_pred <- runif(500)     # Test predictions
# Compute only partial AUC metrics (500 iterations)
results <- auc_parallel(test_pred, bg_pred,
threshold = 5.0,
iterations = 100)  # Reduced for example
results
//' Compute Binned Classification Matrix for AUC Calculation
?bamm::csd_estimate
citation("bamm")
